{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GPT-2conversation_117M_checkpoint81_example_code.ipynb","provenance":[{"file_id":"1ENrM7XatuetdcBOIlk0RhPqI18SphBxI","timestamp":1619942172742},{"file_id":"https://github.com/ak9250/gpt-2-colab/blob/master/GPT_2.ipynb","timestamp":1552094285119}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"iLXW02eIYpcB"},"source":["clone and cd into repo"]},{"cell_type":"code","metadata":{"id":"ICYu3w9hIJkC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621003037236,"user_tz":-180,"elapsed":4876,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"c0c0e44c-0bdc-494d-eaad-af20ea61cd5f"},"source":["# first download the gpt-2 code\n","!git clone https://github.com/nshepperd/gpt-2.git"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Cloning into 'gpt-2'...\n","remote: Enumerating objects: 435, done.\u001b[K\n","remote: Counting objects: 100% (64/64), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 435 (delta 19), reused 48 (delta 13), pack-reused 371\u001b[K\n","Receiving objects: 100% (435/435), 4.48 MiB | 12.29 MiB/s, done.\n","Resolving deltas: 100% (220/220), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cBvmbwX7ePev","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620976145824,"user_tz":-180,"elapsed":1448,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"d9f26536-8260-460c-a2dc-87cb8a581204"},"source":["!pwd"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6eEIs3ApZUVO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621003042080,"user_tz":-180,"elapsed":1458,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"c0ae4c14-6b4f-4725-8a17-dd9421c7474a"},"source":["cd gpt-2"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/gpt-2\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Qtn1qZPgZLb0"},"source":["install requirements"]},{"cell_type":"code","metadata":{"id":"434oOx0bZH6J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621003062958,"user_tz":-180,"elapsed":18637,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"6739338c-b1ce-4231-a8c3-f7020df14f83"},"source":["!pip3 install -r requirements.txt"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting fire>=0.1.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/07/a119a1aa04d37bc819940d95ed7e135a7dcca1c098123a3764a6dcace9e7/fire-0.4.0.tar.gz (87kB)\n","\u001b[K     |████████████████████████████████| 92kB 3.8MB/s \n","\u001b[?25hCollecting regex==2017.4.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/62/c0c0d762ffd4ffaf39f372eb8561b8d491a11ace5a7884610424a8b40f95/regex-2017.04.05.tar.gz (601kB)\n","\u001b[K     |████████████████████████████████| 604kB 6.7MB/s \n","\u001b[?25hCollecting requests==2.21.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/e3/20f3d364d6c8e5d2353c72a67778eb189176f08e873c9900e10c0287b84b/requests-2.21.0-py2.py3-none-any.whl (57kB)\n","\u001b[K     |████████████████████████████████| 61kB 7.9MB/s \n","\u001b[?25hCollecting tqdm==4.31.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/4b/c38b5144cf167c4f52288517436ccafefe9dc01b8d1c190e18a6b154cd4a/tqdm-4.31.1-py2.py3-none-any.whl (48kB)\n","\u001b[K     |████████████████████████████████| 51kB 5.7MB/s \n","\u001b[?25hCollecting toposort==1.5\n","  Downloading https://files.pythonhosted.org/packages/e9/8a/321cd8ea5f4a22a06e3ba30ef31ec33bea11a3443eeb1d89807640ee6ed4/toposort-1.5-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.15.0)\n","Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from fire>=0.1.3->-r requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (3.0.4)\n","Collecting idna<2.9,>=2.5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl (58kB)\n","\u001b[K     |████████████████████████████████| 61kB 8.5MB/s \n","\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests==2.21.0->-r requirements.txt (line 3)) (2020.12.5)\n","Building wheels for collected packages: fire, regex\n","  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115928 sha256=df38f1c13f88ff9bbd5059a778214bebddf91edb343bca60cd2c9a008a955c18\n","  Stored in directory: /root/.cache/pip/wheels/af/19/30/1ea0cad502dcb4e66ed5a690279628c827aea38bbbab75d5ed\n","  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for regex: filename=regex-2017.4.5-cp37-cp37m-linux_x86_64.whl size=534388 sha256=350a91517e2d6027039bdce9e2a3450af67826e855dba6eddf3d5cedb57293d0\n","  Stored in directory: /root/.cache/pip/wheels/75/07/38/3c16b529d50cb4e0cd3dbc7b75cece8a09c132692c74450b01\n","Successfully built fire regex\n","\u001b[31mERROR: spacy 2.2.4 has requirement tqdm<5.0.0,>=4.38.0, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.23.0, but you'll have requests 2.21.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: fbprophet 0.7.1 has requirement tqdm>=4.36.1, but you'll have tqdm 4.31.1 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","Installing collected packages: fire, regex, idna, requests, tqdm, toposort\n","  Found existing installation: regex 2019.12.20\n","    Uninstalling regex-2019.12.20:\n","      Successfully uninstalled regex-2019.12.20\n","  Found existing installation: idna 2.10\n","    Uninstalling idna-2.10:\n","      Successfully uninstalled idna-2.10\n","  Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed fire-0.4.0 idna-2.8 regex-2017.4.5 requests-2.21.0 toposort-1.5 tqdm-4.31.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"o1hrgeKFYsuE"},"source":["download the model"]},{"cell_type":"code","metadata":{"id":"nQUZAa9cIcTY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1620976223038,"user_tz":-180,"elapsed":19003,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"3b3ca612-4a82-480f-f2f2-4c41f9aba662"},"source":["# download the pretrained model\n","#!python download_model.py 1558M\n","#!python download_model.py 117M\n","# 345M"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fetching checkpoint: 1.00kit [00:00, 1.02Mit/s]                                                     \n","Fetching encoder.json: 1.04Mit [00:00, 5.63Mit/s]                                                   \n","Fetching hparams.json: 1.00kit [00:00, 1.07Mit/s]                                                   \n","Fetching model.ckpt.data-00000-of-00001: 498Mit [00:16, 29.6Mit/s]                                  \n","Fetching model.ckpt.index: 6.00kit [00:00, 5.76Mit/s]                                               \n","Fetching model.ckpt.meta: 472kit [00:00, 4.23Mit/s]                                                 \n","Fetching vocab.bpe: 457kit [00:00, 3.20Mit/s]                                                       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7oJPQtdLbbeK"},"source":["!export PYTHONIOENCODING=UTF-8"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UrV4qjoWc8ej","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621003178424,"user_tz":-180,"elapsed":104384,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"1ad088cd-1ff6-47ce-e17c-90b4ac9c0d8b"},"source":["!pip uninstall --yes tensorflow\n","!pip install tensorflow==1.15 "],"execution_count":null,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-2.4.1:\n","  Successfully uninstalled tensorflow-2.4.1\n","Collecting tensorflow==1.15\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n","\u001b[K     |████████████████████████████████| 412.3MB 43kB/s \n","\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n","Collecting keras-applications>=1.0.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n","\u001b[K     |████████████████████████████████| 51kB 6.5MB/s \n","\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n","Collecting tensorboard<1.16.0,>=1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 32.5MB/s \n","\u001b[?25hCollecting gast==0.2.2\n","  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n","Collecting tensorflow-estimator==1.15.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n","\u001b[K     |████████████████████████████████| 512kB 30.4MB/s \n","\u001b[?25hRequirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (56.1.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n","Building wheels for collected packages: gast\n","  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=e25e20dbeef59cf6fd9b30816a6450c474e05c79940e58935c8c8f18f2b664f6\n","  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n","Successfully built gast\n","\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n","Installing collected packages: keras-applications, tensorboard, gast, tensorflow-estimator, tensorflow\n","  Found existing installation: tensorboard 2.4.1\n","    Uninstalling tensorboard-2.4.1:\n","      Successfully uninstalled tensorboard-2.4.1\n","  Found existing installation: gast 0.3.3\n","    Uninstalling gast-0.3.3:\n","      Successfully uninstalled gast-0.3.3\n","  Found existing installation: tensorflow-estimator 2.4.0\n","    Uninstalling tensorflow-estimator-2.4.0:\n","      Successfully uninstalled tensorflow-estimator-2.4.0\n","Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UUw5FEn-fIqW"},"source":["import sys\n","sys.path.append(\"/content/gpt-2/src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qgs6ekD1fItO"},"source":["import fire\n","import json\n","import os\n","import numpy as np\n","import tensorflow as tf\n","\n","import model, sample, encoder"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Hqb_vDxfMza"},"source":["import generate_unconditional_samples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iRMB0HAjhC2v"},"source":["import interactive_conditional_samples"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LibxvQuQ4HGE","executionInfo":{"status":"ok","timestamp":1621003216139,"user_tz":-180,"elapsed":24497,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"f1657581-a587-466c-a43f-77940018e403"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hvkAIuq5fb3d"},"source":["class GPT2:\n","\n","  \n","  # extracted from the source code to generate some text based on a prior\n","  def __init__(\n","      self,\n","      model_name='117M',\n","      seed=None,\n","      nsamples=1,\n","      batch_size=1,\n","      length=None,\n","      temperature=1,\n","      top_k=0,\n","      raw_text=\"\",\n","  ):\n","      \"\"\"\n","      Interactively run the model\n","      :model_name=117M : String, which model to use\n","      :seed=None : Integer seed for random number generators, fix seed to reproduce\n","       results\n","      :nsamples=1 : Number of samples to return total\n","      :batch_size=1 : Number of batches (only affects speed/memory).  Must divide nsamples.\n","      :length=None : Number of tokens in generated text, if None (default), is\n","       determined by model hyperparameters\n","      :temperature=1 : Float value controlling randomness in boltzmann\n","       distribution. Lower temperature results in less random completions. As the\n","       temperature approaches zero, the model will become deterministic and\n","       repetitive. Higher temperature results in more random completions.\n","      :top_k=0 : Integer value controlling diversity. 1 means only 1 word is\n","       considered for each step (token), resulting in deterministic completions,\n","       while 40 means 40 words are considered at each step. 0 (default) is a\n","       special setting meaning no restrictions. 40 generally is a good value.\n","      \"\"\"\n","      if batch_size is None:\n","          batch_size = 1\n","      assert nsamples % batch_size == 0\n","\n","      self.nsamples = nsamples\n","      self.batch_size = batch_size\n","      \n","      my_model_path = \"/content/gdrive/MyDrive/Colab Notebooks/NLP/project/\"   # your path to the model files\n","      self.enc = encoder.get_encoder(model_name, my_model_path)  # --------------------------------------\n","      hparams = model.default_hparams()\n","\n","      with open(os.path.join(my_model_path, model_name, 'hparams.json')) as f:\n","          hparams.override_from_dict(json.load(f))\n","\n","      if length is None:\n","          length = hparams.n_ctx // 2\n","      elif length > hparams.n_ctx:\n","          raise ValueError(\"Can't get samples longer than window size: %s\" % hparams.n_ctx)\n","\n","      self.sess = tf.Session(graph=tf.Graph())\n","      self.sess.__enter__()\n","      \n","      self.context = tf.placeholder(tf.int32, [batch_size, None])\n","      np.random.seed(seed)\n","      tf.set_random_seed(seed)\n","      self.output = sample.sample_sequence(\n","          hparams=hparams, length=length,\n","          context=self.context,\n","          batch_size=batch_size,\n","          temperature=temperature, top_k=top_k\n","      )\n","\n","      saver = tf.train.Saver()\n","      self.ckpt = tf.train.latest_checkpoint(os.path.join(my_model_path, model_name))\n","\n","      saver.restore(self.sess, self.ckpt)\n","\n","  # ei kasutata\n","  def close(self):\n","    self.sess.close()\n","  \n","  def generate_conditional(self,raw_text):\n","      context_tokens = self.enc.encode(raw_text)\n","      for _ in range(self.nsamples // self.batch_size):\n","          out = self.sess.run(self.output, feed_dict={\n","              self.context: [context_tokens for _ in range(self.batch_size)]\n","          })[:, len(context_tokens):]\n","          for i in range(self.batch_size):\n","              text = self.enc.decode(out[i])\n","              return text\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CoJbf02UOFed","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621003268173,"user_tz":-180,"elapsed":31259,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"f5e58a28-1aed-447d-9c51-48513594922a"},"source":["#gpt2 = GPT2(model_name=\"117M\")\n","gpt2 = GPT2(model_name=\"117M_81\")\n","# you must also call download_model.py (see earlier cell) with the correct parameter\n","# 1558M, best results takes a long time to load\n","# 1558M, 774M, 355M, 345M, 124M, and 117M"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /content/gpt-2/src/sample.py:60: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","WARNING:tensorflow:From /content/gpt-2/src/sample.py:65: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.random.categorical` instead.\n","INFO:tensorflow:Restoring parameters from /content/gdrive/MyDrive/Colab Notebooks/NLP/project/117M_81/model-81756\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u2epsBUCPtcc"},"source":["# gpt2.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oAdyhE0JgFV6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1621003280897,"user_tz":-180,"elapsed":11102,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"17b2c1c7-cb08-4c76-c5c0-bb89672a9c4d"},"source":["result = gpt2.generate_conditional(raw_text=\"Can you tell me something about music?\")\n","\n","print(result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","<|endoftext|>\n","I -- I don't know. Um, I don't <u>know</u> music. Why did you bring me in -- why?\n","Is there anything you don't know about it?\n","<|endoftext|>\n","Please! Please!\n","'Cause I didn't.\n","<|endoftext|>\n","I'm sorry about the sound. Cause that was unreal.\n","Even we recording people think we're doing this as a joke. But why should we?\n","<|endoftext|>\n","No thank you. God we were in chains. You don't hear an earthquake from here? Let's get some air in this wind. These men don't have dif----ed, dif----solution in time. Getting analyzed will help, of course, but what's on my mind --\n","No, that's fine.\n","<|endoftext|>\n","Joel's just doing a job, I understand. And you break off his demo --\n","So Joel had to do something to his accident?\n","<|endoftext|>\n","So Joel had to do something to his accident?\n","He's the only person I can really <u>stand</u> on. So what?\n","<|endoftext|>\n","He's the only person I can really <u>stand</u> on. So what?\n","He looks like <u>this</u> business?\n","<|endoftext|>\n","-- an <u>enlarged</u> heart: -- then <u>sudden</u> heart palm --\n","I want it to be <u>this</u>...\n","<|endoftext|>\n","Prick, memory...? Oh --\n","<|endoftext|>\n","-- dissolve the readings in water; history is written --\n","-- Jesus, c'mon --\n","<|endoftext|>\n","Is that her, his, machine...?!\n","Look at my index finger --\n","<|endoftext|>\n","What <u>is</u> that? Have you ever had <u>pregnant</u> feeling?\n","-- We used <u>Al</u>...\n","<|endoftext|>\n","rotten statuses?\n","I don't mean the wounds....\n","<|endoftext|>\n","We need blood!\n","-- Wait\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"erXh3GvcP1Ps"},"source":["class Who:\n","  \"\"\"A class defining the conversation parties: me, he\"\"\"\n","  def __init__(self):\n","    self.prefixes = []\n","\n","  def matches(self,phrase):\n","    for prefix in self.prefixes:\n","      if phrase.startswith(prefix):\n","        #print(f\"{phrase} starts with {prefix}\")\n","        return True\n","      \n","    #print(f\"{phrase} does not start with {self.prefixes}\")\n","    return False\n","\n","  def get_random_prefix(self):\n","    return self.prefixes[0]\n","  \n","class Bot(Who):\n","  def __init__(self):\n","    super().__init__()\n","    self.prefixes = [\"Bot said: \\\"\"]\n","   \n","  \n","class You(Who):\n","  def __init__(self):\n","    super().__init__()\n","    self.prefixes = [\"You said: \\\"\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjS58QZlrVKN"},"source":["class Conversation:\n","  \n","  def __init__(self, prior = None):\n","    if prior is None:\n","      prior=\"\"\"\n","      You said: \"Nice to meet you. What's your name?\"\n","      Bot said: \"My name is Pete.\"\n","      You said: \"That's an interesting name. How old are you?\"\n","      Bot said: \"I'm 40 years old.\"\n","      You said: \"Can you tell me something about yourself?\"\n","      Bot said: \"Ofcourse! I like playing video games and eating cake. \"\n","      You said: \"I like sweet stuff too. What are your plans for tomorrow?\"\n","      \"\"\"\n","    self.suggestion = None\n","    \n","    self.me = Bot()\n","    self.you = You()\n","    self.parties  = [ self.me, self.you ]\n","    \n","    self.conversation = []\n","    \n","    lines = prior.split(\"\\n\")\n","    for line in lines:\n","      line = line.strip()\n","      if len(line)!=0:\n","        party = None\n","        for party in self.parties:\n","          if party.matches(line):\n","            break\n","        if party is None:\n","          raise Exception(f\"Unknown party: {line}\")\n","                \n","        self.conversation.append((party,line))\n","    self.get_suggestion()\n","    \n","  \n","  def get_prior(self):\n","    conv = \"\"\n","    for (party, line) in self.conversation:\n","      conv+=line+\"\\n\"\n","    return conv\n","  \n","  def get_suggestion(self):\n","    who, last_line = self.conversation[-1]\n","\n","    party_index = self.parties.index(who)\n","    next_party = self.parties[(party_index+1) % len(self.parties)]\n","      \n","    conv = self.get_prior()\n","    conv += next_party.get_random_prefix()\n","    answer = self.get_answer(next_party, conv)\n","\n","    if not next_party.matches(answer):\n","      prefix = next_party.get_random_prefix()\n","      answer = prefix + answer\n","    \n","    self.suggestion = (next_party, answer)\n","  \n","  def next(self, party = None, answer = \"\"):\n","    \"\"\"Continue the conversation\n","    :param party: None -> use the current party which is currently in turn\n","    :param answer: None -> use the suggestion, specify a text to override the \n","           suggestion\n","    \n","    \"\"\"\n","    suggested_party, suggested_answer = self.suggestion\n","    if party is None:\n","      party = suggested_party\n","    \n","    if answer == \"\":\n","      answer = suggested_answer\n","      \n","    if not party.matches(answer):\n","      prefix = party.get_random_prefix()\n","      answer = prefix + answer\n","    \n","    answer = answer.strip()\n","    if answer[-1] != \"\\\"\":\n","      # add the closing \"\n","      answer += \"\\\"\"\n","      \n","    self.conversation.append((party, answer))    \n","    self.get_suggestion()\n","    \n","  def retry(self):\n","    self.get_suggestion()\n","        \n","  def get_answer(self, party, conv):\n","    answer = gpt2.generate_conditional(raw_text=conv)\n","    lines = answer.split(\"\\n\")\n","    line = \"\"\n","    for line in lines:\n","      if line !=\"\":\n","        break\n","      \n","    if line!=\"\":\n","      return line\n","    \n","    return \"\"\n","      \n","  def show(self):\n","    conv = \"\"\n","    for (party, line) in self.conversation:\n","      conv+=line+\"\\n\"\n","    print(conv)\n","    if self.suggestion is not None:\n","      party, answer  = self.suggestion\n","      print(\"--> \"+answer)\n","    \n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tOGXtrEaGuKJ"},"source":["#from IPython.display import clear_output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"adEx6UoBK-vR"},"source":["#c = Conversation() \n","\n","def CLI():\n","  #######################################\n","  c = Conversation()  # kommenteeri välja kui ei taha iga kord dialoogi uuesti algusest alustada\n","  #######################################\n","  cmdl = ''\n","  while True:\n","    print(\"-------------------------------------\\nPrior conversation:\\n\")\n","    c.show()\n","    print(\"\\nAre you satisfied with the generated answer? (y/n) ('y' means you can continue on with this answer, 'n' means a new response is generated) Type 'exit' to quit.\")\n","    cmdl = str(input(\">>>\"))\n","    cmdl = cmdl.lower()\n","    cmdl = cmdl.strip()\n","    if cmdl == \"exit\":\n","      print(\"Bye!\")\n","      break\n","    elif cmdl == \"n\":\n","      #clear_output()\n","      print(\"Generating new response. Please wait a bit.\")\n","      c.retry()\n","    elif cmdl == \"y\":\n","      #clear_output()\n","      c.next() # accept the answer\n","      print(\"Please give your reply:\")\n","      cmdl = str(input(\">>>\"))\n","      cmdl = cmdl.lower()\n","      cmdl = cmdl.strip()\n","      c.next(c.you, cmdl)\n","    else:\n","      print(\"This is not valid input!\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3w-Z_i0TK-yJ","executionInfo":{"status":"ok","timestamp":1620982953348,"user_tz":-180,"elapsed":232783,"user":{"displayName":"Kaire Koljal","photoUrl":"https://lh4.googleusercontent.com/-yYw-aPWzx8M/AAAAAAAAAAI/AAAAAAAAAKQ/UNpLXVjHQHo/s64/photo.jpg","userId":"10414226294649667036"}},"outputId":"6b7581d6-87c2-44c9-f168-bba3684976ed"},"source":["CLI()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["-------------------------------------\n","Prior conversation:\n","\n","You said: \"Nice to meet you. What's your name?\"\n","Bot said: \"My name is Pete.\"\n","You said: \"That's an interesting name. How old are you?\"\n","Bot said: \"I'm 40 years old.\"\n","You said: \"Can you tell me something about yourself?\"\n","Bot said: \"Ofcourse! I like playing video games and eating cake. \"\n","You said: \"I like sweet stuff too. What are your plans for tomorrow?\"\n","\n","--> Bot said: \"I'm working on a video game. I would love to play the new Nintendo game. It's crazy fun. \"\n","\n","Are you satisfied with the generated answer? (y/n) ('y' means you can continue on with this answer, 'n' means a new response is generated) Type 'exit' to quit.\n",">>>y\n","Please give your reply:\n",">>>so you plan on playing games all day?\n","-------------------------------------\n","Prior conversation:\n","\n","You said: \"Nice to meet you. What's your name?\"\n","Bot said: \"My name is Pete.\"\n","You said: \"That's an interesting name. How old are you?\"\n","Bot said: \"I'm 40 years old.\"\n","You said: \"Can you tell me something about yourself?\"\n","Bot said: \"Ofcourse! I like playing video games and eating cake. \"\n","You said: \"I like sweet stuff too. What are your plans for tomorrow?\"\n","Bot said: \"I'm working on a video game. I would love to play the new Nintendo game. It's crazy fun. \"\n","You said: \"so you plan on playing games all day?\"\n","\n","--> Bot said: \"Yeah, gym, girl, but I'm working on a new music record. \"\n","\n","Are you satisfied with the generated answer? (y/n) ('y' means you can continue on with this answer, 'n' means a new response is generated) Type 'exit' to quit.\n",">>>y\n","Please give your reply:\n",">>>really? what genre?\n","-------------------------------------\n","Prior conversation:\n","\n","You said: \"Nice to meet you. What's your name?\"\n","Bot said: \"My name is Pete.\"\n","You said: \"That's an interesting name. How old are you?\"\n","Bot said: \"I'm 40 years old.\"\n","You said: \"Can you tell me something about yourself?\"\n","Bot said: \"Ofcourse! I like playing video games and eating cake. \"\n","You said: \"I like sweet stuff too. What are your plans for tomorrow?\"\n","Bot said: \"I'm working on a video game. I would love to play the new Nintendo game. It's crazy fun. \"\n","You said: \"so you plan on playing games all day?\"\n","Bot said: \"Yeah, gym, girl, but I'm working on a new music record. \"\n","You said: \"really? what genre?\"\n","\n","--> Bot said: \"Fascinating stories. \"\n","\n","Are you satisfied with the generated answer? (y/n) ('y' means you can continue on with this answer, 'n' means a new response is generated) Type 'exit' to quit.\n",">>>exit\n","Bye!\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0GXYpaJkK-0n"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sX0aYbH8GuM6"},"source":[""],"execution_count":null,"outputs":[]}]}